{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XNrdUJhYAIs"
      },
      "source": [
        "<h1>Content</h1>\n",
        "<ol>\n",
        "<li>Setup Colab Environment</li>\n",
        "<li>Data augmentation</li>\n",
        "<li>Detection</li>\n",
        "<ol>\n",
        "<li>Training\n",
        "<li>Evaluation\n",
        "</ol>\n",
        "<li>Recognition</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EuJBsOON6B"
      },
      "source": [
        "# Setup Colab Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTyO0_fsOtR3",
        "outputId": "a594368c-3c9e-4dda-8f5e-15fe7edd2321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'PROJECT_EAR_DETECTION'...\n",
            "remote: Enumerating objects: 100216, done.\u001b[K\n",
            "remote: Total 100216 (delta 0), reused 0 (delta 0), pack-reused 100216\u001b[K\n",
            "Receiving objects: 100% (100216/100216), 628.28 MiB | 21.73 MiB/s, done.\n",
            "Resolving deltas: 100% (19560/19560), done.\n",
            "Updating files: 100% (184850/184850), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/jakhin03/PROJECT_EAR_DETECTION\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZF0vQ8EQlaw",
        "outputId": "dcf3ee50-b5f6-41cc-acfd-4a1fa1c3b053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.10/dist-packages (8.0.235)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.22.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.1.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.16.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.1.1.post2209072238)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.12.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X778LOZAYlaj"
      },
      "outputs": [],
      "source": [
        "pwd = \"./\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRTEh_u6h4QC"
      },
      "source": [
        "# Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YL7490EwdM70"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ZaLVo6dbNz"
      },
      "source": [
        "Set the path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WtoGoNaRelZN"
      },
      "outputs": [],
      "source": [
        "dataset=\"EarVN1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "KHfpsjKOdSBR"
      },
      "outputs": [],
      "source": [
        "dataset_path = '%s/data/datasets/%s/Images'%(pwd,dataset)\n",
        "train_path = '%s/data/data_train/%s/train'%(pwd,dataset)\n",
        "valid_path = '%s/data/data_train/%s/val'%(pwd,dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f0t22Bjhafj"
      },
      "source": [
        "Set the percentage of data for validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Y3Lv8l5ghfi5"
      },
      "outputs": [],
      "source": [
        "validation_split = 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VoYeOtghg6y"
      },
      "source": [
        "Split datasets and move to respective directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Mkwfojl4hv6p"
      },
      "outputs": [],
      "source": [
        "# Iterate through the subject subdirectories\n",
        "for subject_dir in os.listdir(dataset_path):\n",
        "    subject_path = os.path.join(dataset_path, subject_dir)\n",
        "\n",
        "    # Create the training and validation subdirectories\n",
        "    train_subject_path = os.path.join(train_path, subject_dir)\n",
        "    valid_subject_path = os.path.join(valid_path, subject_dir)\n",
        "    os.makedirs(train_subject_path, exist_ok=True)\n",
        "    os.makedirs(valid_subject_path, exist_ok=True)\n",
        "\n",
        "    # Collect the image file paths\n",
        "    image_paths = [os.path.join(subject_path, image_file) for image_file in os.listdir(subject_path)]\n",
        "    num_images = len(image_paths)\n",
        "\n",
        "    # Shuffle the image paths\n",
        "    random.shuffle(image_paths)\n",
        "\n",
        "    # Split the dataset\n",
        "    num_valid_images = int(num_images * validation_split)\n",
        "    valid_images = image_paths[:num_valid_images]\n",
        "    train_images = image_paths[num_valid_images:]\n",
        "\n",
        "    # Move the images to the respective directories\n",
        "    for image_path in train_images:\n",
        "        shutil.copy(image_path, train_subject_path)\n",
        "\n",
        "    for image_path in valid_images:\n",
        "        shutil.copy(image_path, valid_subject_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eI3aNFTkiwW8"
      },
      "source": [
        "Training data transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mqCBm2wLiyYr"
      },
      "outputs": [],
      "source": [
        "augment_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=(-15, 15)),\n",
        "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=(5, 5))], p=0.5),\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rowbwDzi1ds"
      },
      "source": [
        "Save transformed images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGD3BoG8N_Az"
      },
      "source": [
        "# Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bBQlpBzeaQMg"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "243MRwbGYUck"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPiucnZ7cbt0"
      },
      "source": [
        "Load a pretrained YOLO model from ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yDfAFJlYcR9"
      },
      "outputs": [],
      "source": [
        "model = YOLO(pwd+\"/Models/yolov8n.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnrvcDgIagJm"
      },
      "source": [
        "Train model on custom datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj4ttyLZaf3p"
      },
      "outputs": [],
      "source": [
        "model.train(data=\"%s/data/data_train/EarVN1/data.yaml\"%pwd, epochs=100)    # running time = 10 minutes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stOC_YsMf2np"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QToSnht9gGpc"
      },
      "source": [
        "### Evaluate on validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnoCF0U-gGAq"
      },
      "outputs": [],
      "source": [
        "metrics = model.val()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0_2WBbAgUoa"
      },
      "source": [
        "<h3>Evaluations on custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDdT3mi8N_A1"
      },
      "source": [
        "### Evalutate the trained model on the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sytCoUpEN_A1"
      },
      "outputs": [],
      "source": [
        "_ = model.val(split='train', save_json=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6caKMAjFN_A2"
      },
      "source": [
        "Evalutate the trained model on the validation dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Td5YuXZeN_A2"
      },
      "outputs": [],
      "source": [
        "_ = model.val(split='val', save_json=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ9Gu0b4N_A3"
      },
      "source": [
        "### Realtime Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulHWEmgjN_A3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4xvDpWN_A3"
      },
      "source": [
        "Load the YOLOv8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1XrTxXXN_A4"
      },
      "outputs": [],
      "source": [
        "model = YOLO('ear_model_5_subjects.pt')\n",
        "# model = YOLO('ear_model_2_subjects.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOw2F4W8N_A4"
      },
      "source": [
        "Define a video capture object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "666RWhPoN_A4"
      },
      "outputs": [],
      "source": [
        "vid = cv2.VideoCapture(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LySlqWIwN_A4"
      },
      "source": [
        "Detection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72n5iWjrN_A5"
      },
      "outputs": [],
      "source": [
        "while(True):\n",
        "\n",
        "    fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "    print('fps:', fps)\n",
        "    # print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
        "\n",
        "    # Capture the video frame by frame\n",
        "    ret, frame = vid.read()\n",
        "\n",
        "    # Run YOLOv8 inference on the frame\n",
        "    results = model(frame)\n",
        "\n",
        "    # Visualize the results on the frame\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # Display the annotated frame\n",
        "    cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
        "\n",
        "    # # Display the resulting frame\n",
        "    # cv2.imshow('frame', frame)\n",
        "\n",
        "    # the 'q' button is set as the quitting button you may use any desired button of your choice\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# After the loop release the cap object\n",
        "vid.release()\n",
        "# Destroy all the windows\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijmJzkYoN_A5"
      },
      "source": [
        "# Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Td-FxfqxN_BA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "import time\n",
        "from datetime import timedelta\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "k_FJ9-4ON_BA"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter(log_dir='./runs')\n",
        "training_dir = '%s/data/data_train/EarVN1/train'%pwd\n",
        "validation_dir = '%s/data/data_train/EarVN1/val'%pwd\n",
        "# https://www.sciencedirect.com/science/article/pii/S2352340919309850"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dulZq9lVN_BB"
      },
      "outputs": [],
      "source": [
        "# input_dim = (32, 64)\n",
        "# input_dim = (64, 128)\n",
        "input_dim = (128, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DqZ_QlN4N_BB"
      },
      "outputs": [],
      "source": [
        "# ImageNet stats\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "# mean = (0.5, 0.5, 0.5)\n",
        "# std = (0.5, 0.5, 0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2BzV2vp7N_BB"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=input_dim),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NOCS51S0N_BC"
      },
      "outputs": [],
      "source": [
        "training_dataset = torchvision.datasets.ImageFolder(root=training_dir, transform=transform)\n",
        "validation_dataset = torchvision.datasets.ImageFolder(root=validation_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QHkioLVGN_BC"
      },
      "outputs": [],
      "source": [
        "train_batch_size = 32\n",
        "val_batch_size = 256\n",
        "train_dataloader = DataLoader(training_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=val_batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXo72uqxN_BD",
        "outputId": "c61a22a4-2a65-4271-a55a-dd40081803f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cache found in C:\\Users\\giakh/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n",
            "c:\\Users\\giakh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\giakh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNeXt50_32X4D_Weights.IMAGENET1K_V1`. You can also use `weights=ResNeXt50_32X4D_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# use resnext\n",
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqzmVIMPN_BD",
        "outputId": "fe71e0aa-e11d-4e87-957a-fab0b71bfa19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cpu device\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mb2coUqxN_BE",
        "outputId": "6e3ccb7c-b013-49b5-c51e-51ddcad844ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 64, 64, 128]           9,408\n",
            "       BatchNorm2d-2          [-1, 64, 64, 128]             128\n",
            "              ReLU-3          [-1, 64, 64, 128]               0\n",
            "         MaxPool2d-4           [-1, 64, 32, 64]               0\n",
            "            Conv2d-5          [-1, 128, 32, 64]           8,192\n",
            "       BatchNorm2d-6          [-1, 128, 32, 64]             256\n",
            "              ReLU-7          [-1, 128, 32, 64]               0\n",
            "            Conv2d-8          [-1, 128, 32, 64]           4,608\n",
            "       BatchNorm2d-9          [-1, 128, 32, 64]             256\n",
            "             ReLU-10          [-1, 128, 32, 64]               0\n",
            "           Conv2d-11          [-1, 256, 32, 64]          32,768\n",
            "      BatchNorm2d-12          [-1, 256, 32, 64]             512\n",
            "           Conv2d-13          [-1, 256, 32, 64]          16,384\n",
            "      BatchNorm2d-14          [-1, 256, 32, 64]             512\n",
            "             ReLU-15          [-1, 256, 32, 64]               0\n",
            "       Bottleneck-16          [-1, 256, 32, 64]               0\n",
            "           Conv2d-17          [-1, 128, 32, 64]          32,768\n",
            "      BatchNorm2d-18          [-1, 128, 32, 64]             256\n",
            "             ReLU-19          [-1, 128, 32, 64]               0\n",
            "           Conv2d-20          [-1, 128, 32, 64]           4,608\n",
            "      BatchNorm2d-21          [-1, 128, 32, 64]             256\n",
            "             ReLU-22          [-1, 128, 32, 64]               0\n",
            "           Conv2d-23          [-1, 256, 32, 64]          32,768\n",
            "      BatchNorm2d-24          [-1, 256, 32, 64]             512\n",
            "             ReLU-25          [-1, 256, 32, 64]               0\n",
            "       Bottleneck-26          [-1, 256, 32, 64]               0\n",
            "           Conv2d-27          [-1, 128, 32, 64]          32,768\n",
            "      BatchNorm2d-28          [-1, 128, 32, 64]             256\n",
            "             ReLU-29          [-1, 128, 32, 64]               0\n",
            "           Conv2d-30          [-1, 128, 32, 64]           4,608\n",
            "      BatchNorm2d-31          [-1, 128, 32, 64]             256\n",
            "             ReLU-32          [-1, 128, 32, 64]               0\n",
            "           Conv2d-33          [-1, 256, 32, 64]          32,768\n",
            "      BatchNorm2d-34          [-1, 256, 32, 64]             512\n",
            "             ReLU-35          [-1, 256, 32, 64]               0\n",
            "       Bottleneck-36          [-1, 256, 32, 64]               0\n",
            "           Conv2d-37          [-1, 256, 32, 64]          65,536\n",
            "      BatchNorm2d-38          [-1, 256, 32, 64]             512\n",
            "             ReLU-39          [-1, 256, 32, 64]               0\n",
            "           Conv2d-40          [-1, 256, 16, 32]          18,432\n",
            "      BatchNorm2d-41          [-1, 256, 16, 32]             512\n",
            "             ReLU-42          [-1, 256, 16, 32]               0\n",
            "           Conv2d-43          [-1, 512, 16, 32]         131,072\n",
            "      BatchNorm2d-44          [-1, 512, 16, 32]           1,024\n",
            "           Conv2d-45          [-1, 512, 16, 32]         131,072\n",
            "      BatchNorm2d-46          [-1, 512, 16, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 16, 32]               0\n",
            "       Bottleneck-48          [-1, 512, 16, 32]               0\n",
            "           Conv2d-49          [-1, 256, 16, 32]         131,072\n",
            "      BatchNorm2d-50          [-1, 256, 16, 32]             512\n",
            "             ReLU-51          [-1, 256, 16, 32]               0\n",
            "           Conv2d-52          [-1, 256, 16, 32]          18,432\n",
            "      BatchNorm2d-53          [-1, 256, 16, 32]             512\n",
            "             ReLU-54          [-1, 256, 16, 32]               0\n",
            "           Conv2d-55          [-1, 512, 16, 32]         131,072\n",
            "      BatchNorm2d-56          [-1, 512, 16, 32]           1,024\n",
            "             ReLU-57          [-1, 512, 16, 32]               0\n",
            "       Bottleneck-58          [-1, 512, 16, 32]               0\n",
            "           Conv2d-59          [-1, 256, 16, 32]         131,072\n",
            "      BatchNorm2d-60          [-1, 256, 16, 32]             512\n",
            "             ReLU-61          [-1, 256, 16, 32]               0\n",
            "           Conv2d-62          [-1, 256, 16, 32]          18,432\n",
            "      BatchNorm2d-63          [-1, 256, 16, 32]             512\n",
            "             ReLU-64          [-1, 256, 16, 32]               0\n",
            "           Conv2d-65          [-1, 512, 16, 32]         131,072\n",
            "      BatchNorm2d-66          [-1, 512, 16, 32]           1,024\n",
            "             ReLU-67          [-1, 512, 16, 32]               0\n",
            "       Bottleneck-68          [-1, 512, 16, 32]               0\n",
            "           Conv2d-69          [-1, 256, 16, 32]         131,072\n",
            "      BatchNorm2d-70          [-1, 256, 16, 32]             512\n",
            "             ReLU-71          [-1, 256, 16, 32]               0\n",
            "           Conv2d-72          [-1, 256, 16, 32]          18,432\n",
            "      BatchNorm2d-73          [-1, 256, 16, 32]             512\n",
            "             ReLU-74          [-1, 256, 16, 32]               0\n",
            "           Conv2d-75          [-1, 512, 16, 32]         131,072\n",
            "      BatchNorm2d-76          [-1, 512, 16, 32]           1,024\n",
            "             ReLU-77          [-1, 512, 16, 32]               0\n",
            "       Bottleneck-78          [-1, 512, 16, 32]               0\n",
            "           Conv2d-79          [-1, 512, 16, 32]         262,144\n",
            "      BatchNorm2d-80          [-1, 512, 16, 32]           1,024\n",
            "             ReLU-81          [-1, 512, 16, 32]               0\n",
            "           Conv2d-82           [-1, 512, 8, 16]          73,728\n",
            "      BatchNorm2d-83           [-1, 512, 8, 16]           1,024\n",
            "             ReLU-84           [-1, 512, 8, 16]               0\n",
            "           Conv2d-85          [-1, 1024, 8, 16]         524,288\n",
            "      BatchNorm2d-86          [-1, 1024, 8, 16]           2,048\n",
            "           Conv2d-87          [-1, 1024, 8, 16]         524,288\n",
            "      BatchNorm2d-88          [-1, 1024, 8, 16]           2,048\n",
            "             ReLU-89          [-1, 1024, 8, 16]               0\n",
            "       Bottleneck-90          [-1, 1024, 8, 16]               0\n",
            "           Conv2d-91           [-1, 512, 8, 16]         524,288\n",
            "      BatchNorm2d-92           [-1, 512, 8, 16]           1,024\n",
            "             ReLU-93           [-1, 512, 8, 16]               0\n",
            "           Conv2d-94           [-1, 512, 8, 16]          73,728\n",
            "      BatchNorm2d-95           [-1, 512, 8, 16]           1,024\n",
            "             ReLU-96           [-1, 512, 8, 16]               0\n",
            "           Conv2d-97          [-1, 1024, 8, 16]         524,288\n",
            "      BatchNorm2d-98          [-1, 1024, 8, 16]           2,048\n",
            "             ReLU-99          [-1, 1024, 8, 16]               0\n",
            "      Bottleneck-100          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-101           [-1, 512, 8, 16]         524,288\n",
            "     BatchNorm2d-102           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-103           [-1, 512, 8, 16]               0\n",
            "          Conv2d-104           [-1, 512, 8, 16]          73,728\n",
            "     BatchNorm2d-105           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-106           [-1, 512, 8, 16]               0\n",
            "          Conv2d-107          [-1, 1024, 8, 16]         524,288\n",
            "     BatchNorm2d-108          [-1, 1024, 8, 16]           2,048\n",
            "            ReLU-109          [-1, 1024, 8, 16]               0\n",
            "      Bottleneck-110          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-111           [-1, 512, 8, 16]         524,288\n",
            "     BatchNorm2d-112           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-113           [-1, 512, 8, 16]               0\n",
            "          Conv2d-114           [-1, 512, 8, 16]          73,728\n",
            "     BatchNorm2d-115           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-116           [-1, 512, 8, 16]               0\n",
            "          Conv2d-117          [-1, 1024, 8, 16]         524,288\n",
            "     BatchNorm2d-118          [-1, 1024, 8, 16]           2,048\n",
            "            ReLU-119          [-1, 1024, 8, 16]               0\n",
            "      Bottleneck-120          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-121           [-1, 512, 8, 16]         524,288\n",
            "     BatchNorm2d-122           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-123           [-1, 512, 8, 16]               0\n",
            "          Conv2d-124           [-1, 512, 8, 16]          73,728\n",
            "     BatchNorm2d-125           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-126           [-1, 512, 8, 16]               0\n",
            "          Conv2d-127          [-1, 1024, 8, 16]         524,288\n",
            "     BatchNorm2d-128          [-1, 1024, 8, 16]           2,048\n",
            "            ReLU-129          [-1, 1024, 8, 16]               0\n",
            "      Bottleneck-130          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-131           [-1, 512, 8, 16]         524,288\n",
            "     BatchNorm2d-132           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-133           [-1, 512, 8, 16]               0\n",
            "          Conv2d-134           [-1, 512, 8, 16]          73,728\n",
            "     BatchNorm2d-135           [-1, 512, 8, 16]           1,024\n",
            "            ReLU-136           [-1, 512, 8, 16]               0\n",
            "          Conv2d-137          [-1, 1024, 8, 16]         524,288\n",
            "     BatchNorm2d-138          [-1, 1024, 8, 16]           2,048\n",
            "            ReLU-139          [-1, 1024, 8, 16]               0\n",
            "      Bottleneck-140          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-141          [-1, 1024, 8, 16]       1,048,576\n",
            "     BatchNorm2d-142          [-1, 1024, 8, 16]           2,048\n",
            "            ReLU-143          [-1, 1024, 8, 16]               0\n",
            "          Conv2d-144           [-1, 1024, 4, 8]         294,912\n",
            "     BatchNorm2d-145           [-1, 1024, 4, 8]           2,048\n",
            "            ReLU-146           [-1, 1024, 4, 8]               0\n",
            "          Conv2d-147           [-1, 2048, 4, 8]       2,097,152\n",
            "     BatchNorm2d-148           [-1, 2048, 4, 8]           4,096\n",
            "          Conv2d-149           [-1, 2048, 4, 8]       2,097,152\n",
            "     BatchNorm2d-150           [-1, 2048, 4, 8]           4,096\n",
            "            ReLU-151           [-1, 2048, 4, 8]               0\n",
            "      Bottleneck-152           [-1, 2048, 4, 8]               0\n",
            "          Conv2d-153           [-1, 1024, 4, 8]       2,097,152\n",
            "     BatchNorm2d-154           [-1, 1024, 4, 8]           2,048\n",
            "            ReLU-155           [-1, 1024, 4, 8]               0\n",
            "          Conv2d-156           [-1, 1024, 4, 8]         294,912\n",
            "     BatchNorm2d-157           [-1, 1024, 4, 8]           2,048\n",
            "            ReLU-158           [-1, 1024, 4, 8]               0\n",
            "          Conv2d-159           [-1, 2048, 4, 8]       2,097,152\n",
            "     BatchNorm2d-160           [-1, 2048, 4, 8]           4,096\n",
            "            ReLU-161           [-1, 2048, 4, 8]               0\n",
            "      Bottleneck-162           [-1, 2048, 4, 8]               0\n",
            "          Conv2d-163           [-1, 1024, 4, 8]       2,097,152\n",
            "     BatchNorm2d-164           [-1, 1024, 4, 8]           2,048\n",
            "            ReLU-165           [-1, 1024, 4, 8]               0\n",
            "          Conv2d-166           [-1, 1024, 4, 8]         294,912\n",
            "     BatchNorm2d-167           [-1, 1024, 4, 8]           2,048\n",
            "            ReLU-168           [-1, 1024, 4, 8]               0\n",
            "          Conv2d-169           [-1, 2048, 4, 8]       2,097,152\n",
            "     BatchNorm2d-170           [-1, 2048, 4, 8]           4,096\n",
            "            ReLU-171           [-1, 2048, 4, 8]               0\n",
            "      Bottleneck-172           [-1, 2048, 4, 8]               0\n",
            "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
            "          Linear-174                 [-1, 1000]       2,049,000\n",
            "================================================================\n",
            "Total params: 25,028,904\n",
            "Trainable params: 25,028,904\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.38\n",
            "Forward/backward pass size (MB): 236.27\n",
            "Params size (MB): 95.48\n",
            "Estimated Total Size (MB): 332.13\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = model.to(device)\n",
        "summary(model, (3, input_dim[0], input_dim[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "CONJLqFNN_BE"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "epochs = 10\n",
        "learning_rate = 1e-3\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RyJfWnvDN_BF"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_function, optimizer, epoch):\n",
        "    model.train()      # set the model in training mode\n",
        "    avg_train_loss, correct = 0, 0\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        predictions = model(X)      # forward propagation\n",
        "        loss = loss_function(predictions, y)        # loss\n",
        "        avg_train_loss += loss.item()\n",
        "        optimizer.zero_grad()   # zero the parameter gradients\n",
        "        loss.backward()         # backpropagation\n",
        "        optimizer.step()\n",
        "        _, predicted = torch.max(predictions.data, 1)  # the class with the highest energy is what we choose as prediction\n",
        "        correct += (predicted == y).sum().item()\n",
        "        if batch % 20 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "    avg_train_loss /= len(dataloader)\n",
        "    train_accuracy = 100*correct/len(dataloader.dataset)\n",
        "    statistics('training', train_accuracy, avg_train_loss, epoch)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tkenh6kpN_BF"
      },
      "outputs": [],
      "source": [
        "def evaluate_validation(dataloader, model, loss_function, epoch):\n",
        "    model.eval()        # set to evaluation model\n",
        "    avg_validation_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for data in dataloader:\n",
        "            images, labels = data[0].to(device), data[1].to(device)\n",
        "            predictions = model(images)\n",
        "            avg_validation_loss += loss_function(predictions, labels).item()       # loss\n",
        "            _, predicted = torch.max(predictions.data, 1)   # the class with the highest energy is what we choose as prediction\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    avg_validation_loss /= len(dataloader)\n",
        "    validation_accuracy = 100*correct/len(dataloader.dataset)\n",
        "    statistics('validation', validation_accuracy, avg_validation_loss, epoch)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "SsHTziEBN_BF"
      },
      "outputs": [],
      "source": [
        "def statistics(dataset, accuracy, loss, epoch):\n",
        "    writer.add_scalar('Loss/' + dataset, loss, epoch)\n",
        "    writer.add_scalar('Accuracy/' + dataset, accuracy, epoch)\n",
        "    print(\"{},\\tLoss: {:.3f}\\t| Accuracy: {:.3f}\".format(dataset.title(), loss, accuracy))\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HG0TFkoqN_BG"
      },
      "outputs": [],
      "source": [
        "def optimize(epochs, train_dataloader, validation_dataloader, model, loss_function, optimizer):\n",
        "    start_time = time.time()\n",
        "    for i in range(epochs):\n",
        "        print(f\"\\nEpoch {i+1}\\n----------------------------------------------\")\n",
        "        train(train_dataloader, model, loss_function, optimizer, i)\n",
        "        evaluate_validation(validation_dataloader, model, loss_function, i)\n",
        "    end_time = time.time()\n",
        "    time_dif = end_time - start_time\n",
        "    print(\"Time usage: \" + str(timedelta(seconds=int(round(time_dif)))))\n",
        "    return"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ny_UPMe-N_BG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kBnORg9N_BG",
        "outputId": "4c69472f-4cfe-482a-b247-84d406ad54fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1\n",
            "----------------------------------------------\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loss: 9.129079  [    0/50071]\n"
          ]
        }
      ],
      "source": [
        "optimize(epochs, train_dataloader, validation_dataloader, model, loss_function, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bykhwpAsN_BH"
      },
      "outputs": [],
      "source": [
        "print('Finished Training')\n",
        "# training time, 3hrs 30 mins\n",
        "torch.save(model.state_dict(), \"ear_classifier.pth\")\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MSFe0l4N_BH"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nHDYnn2N_BI"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ3D1Gs4N_BI"
      },
      "outputs": [],
      "source": [
        "img = Image.open(\"./test_input_ear.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCTxQlDyN_BI"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "path = \"ear_classifier.pth\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4cl42iLN_BJ"
      },
      "outputs": [],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnext50_32x4d', pretrained=False)\n",
        "model = model.to(device)\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LqsjjQoyN_BJ"
      },
      "outputs": [],
      "source": [
        "# ImageNet stats\n",
        "mean = (0.485, 0.456, 0.406)\n",
        "std = (0.229, 0.224, 0.225)\n",
        "# mean = (0.5, 0.5, 0.5)\n",
        "# std = (0.5, 0.5, 0.5)\n",
        "input_dim = (128, 256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eF4eO2VcN_BK"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(size=input_dim),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean, std),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAY1yglMN_BK"
      },
      "outputs": [],
      "source": [
        "input_tensor = transform(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tEuHORoBN_BL"
      },
      "outputs": [],
      "source": [
        "input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension if needed\n",
        "input_tensor = input_tensor.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihh-jm_ZN_BL"
      },
      "outputs": [],
      "source": [
        "input_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuvzL7roN_BL"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    output = model(input_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDdFeZA1N_BM"
      },
      "outputs": [],
      "source": [
        "# Interpret the output\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "predicted_class = torch.argmax(probabilities)\n",
        "print(predicted_class+1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIuT3x9YN_BM"
      },
      "source": [
        "## Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C9vNPLAN_BM"
      },
      "outputs": [],
      "source": [
        "from tensorboard import program\n",
        "import webbrowser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WrILW6HDN_BM"
      },
      "outputs": [],
      "source": [
        "log_dir = './runs/'\n",
        "tb = program.TensorBoard()\n",
        "tb.configure(argv=[None, '--logdir', log_dir])\n",
        "url = tb.launch()\n",
        "print(f\"Tensorflow listening on {url}\")\n",
        "webbrowser.open_new('http://localhost:6006/')\n",
        "\n",
        "# Kill process\n",
        "# Windows\n",
        "# netstat -ano | findstr :6006\n",
        "# taskkill /F /PID {PID}"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "qGD3BoG8N_Az"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
